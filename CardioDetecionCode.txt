Cardio Detection
Tanvir
============================================
#import libraries
import numpy as np
import pandas as pd
import seaborn as sns
===========================================
#load data
from google.colab import files
upload = files.upload()
===========================================
#store data
df = pd.read_csv('cardio.csv')

#print first 7 rows
df.head(7)
===========================================
# importing pandas module 
import pandas as pd 
  
# making data frame from csv file 
nba = pd.read_csv("cardio.csv") 
  
nba 
===========================================
#count empty values
df.isna().sum()
===========================================
#another way to calculate
df.isnull().values.any()
===========================================
#count empty values
df.isna().sum()
===========================================
#view some statistics
df.describe()
===========================================
#count number of patients with and without cardiovascular
df['cardio'].value_counts()
===========================================
#visualize the count
sns.countplot(df['cardio'])
===========================================
#create a year column
df['years'] = (df['age']/365).round(0)
df['years'] = pd.to_numeric(df['years'],downcast = 'integer')

#visualize data
sns.countplot(x='years', hue='cardio', data=df, palette='colorblind', edgecolor=sns.color_palette('dark',n_colors=1))
===========================================
#get the correlation of the column
df.corr()
===========================================
#visualize data
import matplotlib.pyplot as plt
plt.figure(figsize = (20,7))
sns.heatmap(df.corr(),annot=True,fmt = '0%')
===========================================
#remove years column
df=df.drop('years',axis=1)
===========================================
#remove id column
df=df.drop('id',axis=1)
===========================================
#split data into target data
X=df.iloc[:,:-1].values
Y=df.iloc[:,-1].values
===========================================
#split data again into 75% training data and 25% testing data set
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=1)
===========================================
#feature scaling
#scale the values in the data to be values between 0 and 1 inclusive
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)
============================================
#use random forest classifier
from sklearn.ensemble import RandomForestClassifier
forest=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=1)
forest.fit(X_train,Y_train)
============================================
#test the model's accuracy on train data
model=forest
model.score(X_train,Y_train)
============================================
#test the model's accuracy on test data
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(Y_test,model.predict(X_test))

TN=cm[0][0]
TP=cm[1][1]
FN=cm[1][0]
FP=cm[0][1]

#print the confusion matrix
print(cm)

#print accuracy
print('Model test accuracy={}'.format((TP+TN)/(TP+TN+FN+FP)))

